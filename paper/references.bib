@article{cao2023learning,
  title={Learning Large Graph Property Prediction via Graph Segment Training},
  author={Cao, Kaidi and Phothilimthana, Phitchaya Mangpo and Abu-El-Haija, Sami and Zelle, Dustin and Zhou, Yanqi and Mendis, Charith and Leskovec, Jure and Perozzi, Bryan},
  journal={arXiv preprint arXiv:2305.12322},
  year={2023}
}
@article{mangpo2023tpugraphs,
  title={TpuGraphs: A Performance Prediction Dataset on Large Tensor Computational Graphs},
  author={Mangpo, Phitchaya and Abu-El-Haija, Sami and Cao, Kaidi and Fatemi, Bahare and Mendis, Charith and Perozzi, Bryan},
  year={2023}
}
@inproceedings{norrie2020google,
  title={Google's Training Chips Revealed: TPUv2 and TPUv3.},
  author={Norrie, Thomas and Patil, Nishant and Yoon, Doe Hyun and Kurian, George and Li, Sheng and Laudon, James and Young, Cliff and Jouppi, Norman P and Patterson, David A},
  booktitle={Hot Chips Symposium},
  pages={1--70},
  year={2020}
}
@inproceedings{patterson201850,
  title={50 Years of computer architecture: From the mainframe CPU to the domain-specific tpu and the open RISC-V instruction set},
  author={Patterson, David},
  booktitle={2018 IEEE International Solid-State Circuits Conference-(ISSCC)},
  pages={27--31},
  year={2018},
  organization={IEEE}
}
@inproceedings{taugtekin2021foga,
  title={FOGA: flag optimization with genetic algorithm},
  author={Ta{\u{g}}tekin, Burak and H{\"o}ke, Berkan and Sezer, Mert Kutay and {\"O}zt{\"u}rk, Mahiye Uluya{\u{g}}mur},
  booktitle={2021 International Conference on INnovations in Intelligent SysTems and Applications (INISTA)},
  pages={1--6},
  year={2021},
  organization={IEEE}
}
@article{garriga2021exact,
  title={Exact Langevin dynamics with stochastic gradients},
  author={Garriga-Alonso, Adri{\`a} and Fortuin, Vincent},
  journal={arXiv preprint arXiv:2102.01691},
  year={2021}
}
@article{lerer2019pytorch,
  title={Pytorch-biggraph: A large scale graph embedding system},
  author={Lerer, Adam and Wu, Ledell and Shen, Jiajun and Lacroix, Timothee and Wehrstedt, Luca and Bose, Abhijit and Peysakhovich, Alex},
  journal={Proceedings of Machine Learning and Systems},
  volume={1},
  pages={120--131},
  year={2019}
}
@article{xu2018powerful,
  title={How powerful are graph neural networks?},
  author={Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
  journal={arXiv preprint arXiv:1810.00826},
  year={2018}
}
@article{velivckovic2017graph,
  title={Graph attention networks},
  author={Veli{\v{c}}kovi{\'c}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Lio, Pietro and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1710.10903},
  year={2017}
}
@article{kumar2019scale,
  title={Scale mlperf-0.6 models on google tpu-v3 pods},
  author={Kumar, Sameer and Bitorff, Victor and Chen, Dehao and Chou, Chiachen and Hechtman, Blake and Lee, HyoukJoong and Kumar, Naveen and Mattson, Peter and Wang, Shibo and Wang, Tao and others},
  journal={arXiv preprint arXiv:1909.09756},
  year={2019}
}
@article{bessonov2023recurrent,
  title={Recurrent Memory Decision Transformer},
  author={Bessonov, Arkadii and Staroverov, Alexey and Zhang, Huzhenyu and Kovalev, Alexey K and Yudin, Dmitry and Panov, Aleksandr I},
  journal={arXiv preprint arXiv:2306.09459},
  year={2023}
}
@article{dai2019transformer,
  title={Transformer-xl: Attentive language models beyond a fixed-length context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1901.02860},
  year={2019}
}
@article{rampavsek2022recipe,
  title={Recipe for a general, powerful, scalable graph transformer},
  author={Ramp{\'a}{\v{s}}ek, Ladislav and Galkin, Michael and Dwivedi, Vijay Prakash and Luu, Anh Tuan and Wolf, Guy and Beaini, Dominique},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={14501--14515},
  year={2022}
}
@inproceedings{chen2022nagphormer,
  title={NAGphormer: A tokenized graph transformer for node classification in large graphs},
  author={Chen, Jinsong and Gao, Kaiyuan and Li, Gaichao and He, Kun},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}
@article{zhang2023large,
  title={Large graph models: A perspective},
  author={Zhang, Ziwei and Li, Haoyang and Zhang, Zeyang and Qin, Yijian and Wang, Xin and Zhu, Wenwu},
  journal={arXiv preprint arXiv:2308.14522},
  year={2023}
}
@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{jouppi2023tpu,
  title={Tpu v4: An optically reconfigurable supercomputer for machine learning with hardware support for embeddings},
  author={Jouppi, Norm and Kurian, George and Li, Sheng and Ma, Peter and Nagarajan, Rahul and Nai, Lifeng and Patil, Nishant and Subramanian, Suvinay and Swing, Andy and Towles, Brian and others},
  booktitle={Proceedings of the 50th Annual International Symposium on Computer Architecture},
  pages={1--14},
  year={2023}
}
@article{artemev2022memory,
  title={Memory safe computations with XLA compiler},
  author={Artemev, Artem and An, Yuze and Roeder, Tilman and van der Wilk, Mark},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={18970--18982},
  year={2022}
}
